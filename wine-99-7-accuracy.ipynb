{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":52633,"sourceType":"datasetVersion","datasetId":35901}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-06T10:37:36.524098Z","iopub.execute_input":"2024-06-06T10:37:36.524471Z","iopub.status.idle":"2024-06-06T10:37:37.714915Z","shell.execute_reply.started":"2024-06-06T10:37:36.524444Z","shell.execute_reply":"2024-06-06T10:37:37.713506Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/wine-quality/winequalityN.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"1)KNN-\n0.9967365967365968 imputer:1 n_neighbours:3 p:1 weights=distance\n{'p': 1, 'weights': 'distance'}\nKNeighborsClassifier(n_neighbors=11, p=1, weights='distance')\n\n2)Logistic Regression\n0.9705878941263315\n{'C': 10.0, 'penalty': 'l1'}\nLogisticRegression(C=10.0, max_iter=1000000, penalty='l1', solver='saga')\n\n3)Naive bayes Gaussian 0.9687645687645687 (without scaling) , .9748251748251748 (min max scaling )0.9902097902097902 (min-max+ power transformer)\n\n4)Naive bayes multinomial 0.9221445221445221 (without scaling) 0.7575757575757576 (with sclaing )\n\n5)Naive bayes bernoulli 0.7757575757575758(without scaling ) 0.7762237762237763 (with sclaing)\n\n6)SVM 0.9967365967365968 {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\nSVC(gamma=1.0)\n\n7)decision tree 0.9967365967365968\n\n8) **bagging classifier svm** **0.9972027972027973**\n\n","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/wine-quality/winequalityN.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:37:40.268206Z","iopub.execute_input":"2024-06-06T10:37:40.268733Z","iopub.status.idle":"2024-06-06T10:37:40.306961Z","shell.execute_reply.started":"2024-06-06T10:37:40.268701Z","shell.execute_reply":"2024-06-06T10:37:40.305863Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(df.info())","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:37:41.731587Z","iopub.execute_input":"2024-06-06T10:37:41.732038Z","iopub.status.idle":"2024-06-06T10:37:41.768072Z","shell.execute_reply.started":"2024-06-06T10:37:41.732006Z","shell.execute_reply":"2024-06-06T10:37:41.766868Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6497 entries, 0 to 6496\nData columns (total 13 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   type                  6497 non-null   object \n 1   fixed acidity         6487 non-null   float64\n 2   volatile acidity      6489 non-null   float64\n 3   citric acid           6494 non-null   float64\n 4   residual sugar        6495 non-null   float64\n 5   chlorides             6495 non-null   float64\n 6   free sulfur dioxide   6497 non-null   float64\n 7   total sulfur dioxide  6497 non-null   float64\n 8   density               6497 non-null   float64\n 9   pH                    6488 non-null   float64\n 10  sulphates             6493 non-null   float64\n 11  alcohol               6497 non-null   float64\n 12  quality               6497 non-null   int64  \ndtypes: float64(11), int64(1), object(1)\nmemory usage: 660.0+ KB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df.head(5))","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:37:44.319521Z","iopub.execute_input":"2024-06-06T10:37:44.319903Z","iopub.status.idle":"2024-06-06T10:37:44.338544Z","shell.execute_reply.started":"2024-06-06T10:37:44.319876Z","shell.execute_reply":"2024-06-06T10:37:44.337132Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"    type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n0  white            7.0              0.27         0.36            20.7   \n1  white            6.3              0.30         0.34             1.6   \n2  white            8.1              0.28         0.40             6.9   \n3  white            7.2              0.23         0.32             8.5   \n4  white            7.2              0.23         0.32             8.5   \n\n   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n0      0.045                 45.0                 170.0   1.0010  3.00   \n1      0.049                 14.0                 132.0   0.9940  3.30   \n2      0.050                 30.0                  97.0   0.9951  3.26   \n3      0.058                 47.0                 186.0   0.9956  3.19   \n4      0.058                 47.0                 186.0   0.9956  3.19   \n\n   sulphates  alcohol  quality  \n0       0.45      8.8        6  \n1       0.49      9.5        6  \n2       0.44     10.1        6  \n3       0.40      9.9        6  \n4       0.40      9.9        6  \n","output_type":"stream"}]},{"cell_type":"code","source":"X=(df.iloc[:,1:])\ny=df[\"type\"]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:37:47.160623Z","iopub.execute_input":"2024-06-06T10:37:47.161029Z","iopub.status.idle":"2024-06-06T10:37:47.169286Z","shell.execute_reply.started":"2024-06-06T10:37:47.160997Z","shell.execute_reply":"2024-06-06T10:37:47.167941Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"y=y.replace({\"red\":1,\"white\":0})","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:37:50.071739Z","iopub.execute_input":"2024-06-06T10:37:50.072162Z","iopub.status.idle":"2024-06-06T10:37:50.081859Z","shell.execute_reply.started":"2024-06-06T10:37:50.072130Z","shell.execute_reply":"2024-06-06T10:37:50.080543Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3619773954.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  y=y.replace({\"red\":1,\"white\":0})\n","output_type":"stream"}]},{"cell_type":"code","source":"print(y)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:37:51.682395Z","iopub.execute_input":"2024-06-06T10:37:51.682809Z","iopub.status.idle":"2024-06-06T10:37:51.690055Z","shell.execute_reply.started":"2024-06-06T10:37:51.682777Z","shell.execute_reply":"2024-06-06T10:37:51.688877Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"0       0\n1       0\n2       0\n3       0\n4       0\n       ..\n6492    1\n6493    1\n6494    1\n6495    1\n6496    1\nName: type, Length: 6497, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:37:54.096489Z","iopub.execute_input":"2024-06-06T10:37:54.096915Z","iopub.status.idle":"2024-06-06T10:37:54.109001Z","shell.execute_reply.started":"2024-06-06T10:37:54.096883Z","shell.execute_reply":"2024-06-06T10:37:54.107662Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# **K NEAREST NEIGHBOURS**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import PowerTransformer, StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\ntransformer = PowerTransformer()\nscaler = MinMaxScaler()\n\n\nweight_options = ['uniform', 'distance']\np=[1,2]\nparam_grid = dict(weights=weight_options,p=p)\n\naccuracy=0;\na=0;\nb=0;\nfor i in range(1,12):\n    for j in range(1,12):\n        imputer = KNNImputer(n_neighbors=j)\n        X_train_imputed = imputer.fit_transform(X_train)\n        X_test_imputed = imputer.transform(X_test)\n        model = KNeighborsClassifier(n_neighbors=i)\n        X_train_transformed = transformer.fit_transform(X_train_imputed)\n        X_test_transformed = transformer.transform(X_test_imputed)\n        scaled_X_train = scaler.fit_transform(X_train_transformed)\n        scaled_X_test = scaler.transform(X_test_transformed)\n        grid = GridSearchCV(model, param_grid, cv=10, scoring='accuracy', return_train_score=False)\n        grid.fit(scaled_X_train, y_train)\n        y_predicted = grid.predict(scaled_X_test)\n        from sklearn.metrics import accuracy_score\n        if(accuracy_score(y_test, y_predicted))>accuracy:\n            accuracy=accuracy_score(y_test, y_predicted);\n            a=i;\n            b=j;\nprint(accuracy,a,b);\n\n\n            \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import PowerTransformer, StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\ntransformer = PowerTransformer()\nscaler = MinMaxScaler()\n\n\nweight_options = ['uniform', 'distance']\np=[1,2]\nparam_grid = dict(weights=weight_options,p=p)\n\n\n\nimputer = KNNImputer(n_neighbors=1)\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)\nmodel = KNeighborsClassifier(n_neighbors=3)\nX_train_transformed = transformer.fit_transform(X_train_imputed)\nX_test_transformed = transformer.transform(X_test_imputed)\nscaled_X_train = scaler.fit_transform(X_train_transformed)\nscaled_X_test = scaler.transform(X_test_transformed)\ngrid = GridSearchCV(model, param_grid, cv=10, scoring='accuracy', return_train_score=False)\ngrid.fit(scaled_X_train, y_train)\ny_predicted = grid.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy);\n            \ncv_scores = cross_val_score(grid, scaled_X_train, y_train, cv=5, scoring='accuracy')\nprint(\"Cross-validation scores: \", cv_scores)\nprint(\"Mean cross-validation score: \", np.mean(cv_scores))\nprint(\"Standard deviation of cross-validation scores: \", np.std(cv_scores))\ncv_scores = cross_val_score(grid, scaled_X_test, y_test, cv=5, scoring='accuracy')\nprint(\"Cross-validation scores: \", cv_scores)\nprint(\"Mean cross-validation score: \", np.mean(cv_scores))\nprint(\"Standard deviation of cross-validation scores: \", np.std(cv_scores))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:37:58.957053Z","iopub.execute_input":"2024-06-06T10:37:58.957439Z","iopub.status.idle":"2024-06-06T10:38:11.658063Z","shell.execute_reply.started":"2024-06-06T10:37:58.957408Z","shell.execute_reply":"2024-06-06T10:38:11.656999Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"0.9967365967365968\nCross-validation scores:  [0.99885189 0.99311137 0.9954023  0.99655172 0.98965517]\nMean cross-validation score:  0.9947144912044552\nStandard deviation of cross-validation scores:  0.0031347512009265812\nCross-validation scores:  [0.99300699 0.997669   0.995338   0.99300699 0.99300699]\nMean cross-validation score:  0.9944055944055943\nStandard deviation of cross-validation scores:  0.0018648018648018516\n","output_type":"stream"}]},{"cell_type":"code","source":"print(grid.best_score_)\nprint(grid.best_params_)\nprint(grid.best_estimator_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **LOGISTIC REGRESSION**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.impute import KNNImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\ngrid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n\n\nimputer = KNNImputer(n_neighbors=1)\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)\nmodel = LogisticRegression(max_iter=1000000,solver=\"saga\")\ngrid = GridSearchCV(model, grid, cv=10, scoring='accuracy', return_train_score=False)\ngrid.fit(X_train_imputed, y_train)\ny_predicted = grid.predict(X_test_imputed)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)\nprint(grid.best_score_)\nprint(grid.best_params_)\nprint(grid.best_estimator_)\n            \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Naive bayes**","metadata":{}},{"cell_type":"code","source":"# without scaling gaussian\nfrom sklearn.naive_bayes import GaussianNB\nimputer = KNNImputer(n_neighbors=1)\nmodel3 = GaussianNB()\nmodel3.fit(X_train_imputed, y_train)\ny_predicted = model3.predict(X_test_imputed)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with min-max scaling gaussian\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaled_X_train = scaler.fit_transform(X_train_imputed)\nscaled_X_test = scaler.transform(X_test_imputed)\nmodel3 = GaussianNB()\nmodel3.fit(scaled_X_train, y_train)\ny_predicted = model3.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with min-max scaling gaussian and power transformer\nfrom sklearn.preprocessing import PowerTransformer, StandardScaler\ntransformer = PowerTransformer()\nX_train_transformed = transformer.fit_transform(X_train_imputed)\nX_test_transformed = transformer.transform(X_test_imputed)\nscaled_X_train = scaler.fit_transform(X_train_transformed)\nscaled_X_test = scaler.transform(X_test_transformed)\nmodel3 = GaussianNB()\nmodel3.fit(scaled_X_train, y_train)\ny_predicted = model3.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#without min-max scaling bernoulli\nfrom sklearn.naive_bayes import BernoulliNB\nmodel3 = BernoulliNB()\nmodel3.fit(X_train_imputed, y_train)\ny_predicted = model3.predict(X_test_imputed)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with min-max scaling bernoulli\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaled_X_train = scaler.fit_transform(X_train_imputed)\nscaled_X_test = scaler.transform(X_test_imputed)\nmodel3 = BernoulliNB()\nmodel3.fit(scaled_X_train, y_train)\ny_predicted = model3.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with min-max scaling bernoulli and power transformer\nfrom sklearn.preprocessing import PowerTransformer, StandardScaler\ntransformer = PowerTransformer()\nX_train_transformed = transformer.fit_transform(X_train_imputed)\nX_test_transformed = transformer.transform(X_test_imputed)\nscaled_X_train = scaler.fit_transform(X_train_transformed)\nscaled_X_test = scaler.transform(X_test_transformed)\nmodel3 = BernoulliNB()\nmodel3.fit(scaled_X_train, y_train)\ny_predicted = model3.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#without min-max scaling multinomial\nfrom sklearn.naive_bayes import MultinomialNB\nmodel3 = MultinomialNB()\nmodel3.fit(X_train_imputed, y_train)\ny_predicted = model3.predict(X_test_imputed)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with min-max scaling multinomial\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaled_X_train = scaler.fit_transform(X_train_imputed)\nscaled_X_test = scaler.transform(X_test_imputed)\nmodel3 = MultinomialNB()\nmodel3.fit(scaled_X_train, y_train)\ny_predicted = model3.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with min-max scaling multi and power transformer\nfrom sklearn.preprocessing import PowerTransformer, StandardScaler\ntransformer = PowerTransformer()\nX_train_transformed = transformer.fit_transform(X_train_imputed)\nX_test_transformed = transformer.transform(X_test_imputed)\nscaled_X_train = scaler.fit_transform(X_train_transformed)\nscaled_X_test = scaler.transform(X_test_transformed)\nmodel3 = MultinomialNB()\nmodel3.fit(scaled_X_train, y_train)\ny_predicted = model3.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SVM**","metadata":{}},{"cell_type":"code","source":"grid={\"C\":[0.1,0.5,1.0], \"gamma\":[0.0,0.5,1.0],\"kernel\":[\"linear\",\"rbf\",\"poly\",\"sigmoid\"]}\nfrom sklearn.svm import SVC\nsvm = SVC(kernel=\"rbf\", gamma=0.5, C=1.0)\ngrid = GridSearchCV(svm, grid, cv=10, scoring='accuracy', return_train_score=False)\ntransformer = PowerTransformer()\nX_train_transformed = transformer.fit_transform(X_train_imputed)\nX_test_transformed = transformer.transform(X_test_imputed)\nscaled_X_train = scaler.fit_transform(X_train_transformed)\nscaled_X_test = scaler.transform(X_test_transformed)\n\ngrid.fit(scaled_X_train, y_train)\ny_predicted = grid.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)\nprint(grid.best_score_)\nprint(grid.best_params_)\nprint(grid.best_estimator_)\n\ncv_scores = cross_val_score(grid, scaled_X_train, y_train, cv=5, scoring='accuracy')\nprint(\"Cross-validation scores: \", cv_scores)\nprint(\"Mean cross-validation score: \", np.mean(cv_scores))\nprint(\"Standard deviation of cross-validation scores: \", np.std(cv_scores))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# **DECISION TREE**","metadata":{}},{"cell_type":"code","source":"\nparam_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n              'ccp_alpha': [0.1, .01, .001],\n              'max_depth' : [5, 6, 7, 8, 9],\n              'criterion' :['gini', 'entropy']\n             }\ntree_clas = DecisionTreeClassifier(random_state=1024)\ngrid_search = GridSearchCV(estimator=tree_clas, param_grid=param_grid, cv=5, verbose=True)\ngrid.fit(scaled_X_train, y_train)\ny_predicted = grid.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **BAGGING CLASSIFIER**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import BaggingClassifier                          \nclf = BaggingClassifier(estimator=SVC(),n_estimators=10, random_state=0).fit(scaled_X_train, y_train)\ny_predicted = clf.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)\n\ncv_scores = cross_val_score(clf, scaled_X_train, y_train, cv=5, scoring='accuracy')\nprint(\"Cross-validation scores: \", cv_scores)\nprint(\"Mean cross-validation score: \", np.mean(cv_scores))\nprint(\"Standard deviation of cross-validation scores: \", np.std(cv_scores))\ncv_scores = cross_val_score(clf, scaled_X_test, y_test, cv=5, scoring='accuracy')\nprint(\"Cross-validation scores: \", cv_scores)\nprint(\"Mean cross-validation score: \", np.mean(cv_scores))\nprint(\"Standard deviation of cross-validation scores: \", np.std(cv_scores))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:07:10.937780Z","iopub.execute_input":"2024-06-06T10:07:10.938189Z","iopub.status.idle":"2024-06-06T10:07:12.882723Z","shell.execute_reply.started":"2024-06-06T10:07:10.938158Z","shell.execute_reply":"2024-06-06T10:07:12.881851Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"0.9972027972027973\nCross-validation scores:  [0.99885189 0.99425947 0.99655172 0.99770115 0.99425287]\nMean cross-validation score:  0.9963234226744262\nStandard deviation of cross-validation scores:  0.0018379601864260643\nCross-validation scores:  [0.99300699 1.         0.99300699 0.995338   0.995338  ]\nMean cross-validation score:  0.9953379953379953\nStandard deviation of cross-validation scores:  0.002553485116574196\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.ensemble import BaggingClassifier                          \n\nparam_grid = {\n    'n_estimators': [10, 50, 100],  \n    'max_samples': [0.5, 1.0],  \n    'max_features': [0.5,1],  \n}\n\ngrid_search = GridSearchCV(BaggingClassifier(estimator=SVC()), param_grid, cv=5, verbose=1)\ngrid_search.fit(scaled_X_train, y_train)\ny_predicted = grid.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)\nprint(grid.best_score_)\nprint(grid.best_params_)\nprint(grid.best_estimator_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.ensemble import BaggingClassifier                          \nclf = BaggingClassifier(estimator=KNeighborsClassifier(),n_estimators=10, random_state=0).fit(scaled_X_train, y_train)\ny_predicted = clf.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom sklearn.ensemble import BaggingClassifier \nfor i in range(1,10):\n    clf = BaggingClassifier(estimator=RandomForestClassifier(),n_estimators=i*10, random_state=0).fit(scaled_X_train, y_train)\n    y_predicted = clf.predict(scaled_X_test)\n    from sklearn.metrics import accuracy_score\n\n    accuracy=accuracy_score(y_test, y_predicted);\n    print(i,accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nclf = GradientBoostingClassifier()\ngradient_boosting_params = {\n    'loss': ['log_loss','exponential'],\n    'learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n    'min_samples_split': np.linspace(0.1, 0.5, 12),\n    'min_samples_leaf': np.linspace(0.1, 0.5, 12),\n    'max_depth': [3, 5, 8],\n    'max_features': ['log2', 'sqrt'],\n    'criterion': ['friedman_mse', 'mae'],\n    'subsample': [0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n    'n_estimators': [10, 50, 100, 200]\n}\n\ngrid = GridSearchCV(clf, gradient_boosting_params, cv=10, scoring='accuracy', return_train_score=False)\ngrid.fit(scaled_X_train, y_train)\ny_predicted = grid.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)\nprint(grid.best_score_)\nprint(grid.best_params_)\nprint(grid.best_estimator_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nmodel = xgb.XGBClassifier()\nxgboost_params = {\n    'n_estimators': [50, 100, 200, 500],\n    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'max_depth': [3, 5, 7, 10],\n    'subsample': [0.5, 0.7, 0.8, 1.0],\n    'colsample_bytree': [0.5, 0.7, 0.8, 1.0]\n}\ngrid = GridSearchCV(model, xgboost_params, cv=10, scoring='accuracy', return_train_score=False)\ngrid.fit(scaled_X_train, y_train)\ny_predicted = grid.predict(scaled_X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test, y_predicted);\nprint(accuracy)\nprint(grid.best_score_)\nprint(grid.best_params_)\nprint(grid.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:18:09.441695Z","iopub.execute_input":"2024-06-06T11:18:09.442097Z","iopub.status.idle":"2024-06-06T11:46:21.397385Z","shell.execute_reply.started":"2024-06-06T11:18:09.442065Z","shell.execute_reply":"2024-06-06T11:46:21.396174Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"0.9953379953379954\n0.9970125487714858\n{'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\nXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=10, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=None, ...)\n","output_type":"stream"}]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import accuracy_score\n\n\nmodel = xgb.XGBClassifier(\n    colsample_bytree=0.8,\n    learning_rate=0.2,\n    max_depth=10,\n    n_estimators=100,\n    subsample=0.5,\n)\nmodel.fit(scaled_X_train, y_train)\ny_predicted = model.predict(scaled_X_test)\naccuracy = accuracy_score(y_test, y_predicted)\nprint(accuracy)\n\ncv_scores = cross_val_score(clf, scaled_X_train, y_train, cv=5, scoring='accuracy')\nprint(\"Cross-validation scores: \", cv_scores)\nprint(\"Mean cross-validation score: \", np.mean(cv_scores))\nprint(\"Standard deviation of cross-validation scores: \", np.std(cv_scores))\ncv_scores = cross_val_score(clf, scaled_X_test, y_test, cv=5, scoring='accuracy')\nprint(\"Cross-validation scores: \", cv_scores)\nprint(\"Mean cross-validation score: \", np.mean(cv_scores))\nprint(\"Standard deviation of cross-validation scores: \", np.std(cv_scores))","metadata":{"execution":{"iopub.status.busy":"2024-06-06T12:03:52.530912Z","iopub.execute_input":"2024-06-06T12:03:52.531298Z","iopub.status.idle":"2024-06-06T12:03:58.971417Z","shell.execute_reply.started":"2024-06-06T12:03:52.531267Z","shell.execute_reply":"2024-06-06T12:03:58.970277Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"0.9953379953379954\nCross-validation scores:  [0.99196326 0.99081515 0.9954023  0.9954023  0.99310345]\nMean cross-validation score:  0.9933372923182496\nStandard deviation of cross-validation scores:  0.0018347930009771191\nCross-validation scores:  [0.98834499 0.99300699 0.98601399 0.98834499 0.98601399]\nMean cross-validation score:  0.9883449883449883\nStandard deviation of cross-validation scores:  0.002553485116574196\n","output_type":"stream"}]}]}